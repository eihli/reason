{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf07789-ffb7-4b78-8304-a08e229a4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import GPT2TokenizerFast \n",
    "import zmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53e48af-4ee5-4d53-a5ca-240883af3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca166ea-6fdb-48f5-ba89-bdd3ed680a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=device).manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7608c706-b7e7-4c9a-8559-fe053352d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 1024\n",
    "BATCH_SIZE=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f0ec03-0720-4523-aa35-942f7a7dc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixing with _ to signify global.\n",
    "_text_tokenizer = GPT2TokenizerFast.from_pretrained(\"openai-community/gpt2\")\n",
    "_text_tokenizer.pad_token = _text_tokenizer.eos_token\n",
    "TOKENIZATION_DEFAULTS = [\n",
    "    (\"max_length\", SEQUENCE_LENGTH),\n",
    "    (\"truncation\", True),\n",
    "    (\"padding\", \"max_length\"),\n",
    "    (\"return_tensors\", \"pt\"),\n",
    "]\n",
    "def tokenize_text(text, device=device, **kwargs):\n",
    "    kwargs = dict(TOKENIZATION_DEFAULTS + list(kwargs.items()))\n",
    "    return _text_tokenizer(text, **kwargs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9035941e-3191-43d2-b08c-50b1959c97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_1 = \"\"\"\n",
    "<INST>\n",
    "(appendo a b '(1 2 3 4))\n",
    "results in order of how similar in length are a and b\n",
    "</INST>\n",
    "<STREAM>\n",
    "  mplus\n",
    "    pause\n",
    "      #s(state ((#s(var a2 388) #s(var a1 390) . #s(var a2 391)) (#s(var res 389) 4) (#s(var a1 387) . 3) (#s(var a2 385) #s(var a1 387) . #s(var a2 388)) (#s(var res 386) 3 4) (#s(var a1 384) . 2) (#s(var a2 382) #s(var a1 384) . #s(var a2 385)) (#s(var res 383) 2 3 4) (#s(var a1 381) . 1) (#s(var a 379) #s(var a1 381) . #s(var a2 382)) (#s(var #f 0) #s(var a 379) #s(var b 380))) () () ())\n",
    "      == #s(var res 389) (#s(var a1 390) . #s(var res 392))\n",
    "    bind\n",
    "      #f\n",
    "      == #s(var res 389) (#s(var a1 390) . #s(var res 392))\n",
    "</STREAM>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df70698-f911-45bc-af48-a24913968d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_2 = \"\"\"\n",
    "  mplus\n",
    "    mplus\n",
    "      pause\n",
    "        #s(state ((#s(var a2 388)) (#s(var res 389) 4) (#s(var a1 387) . 3) (#s(var a2 385) #s(var a1 387) . #s(var a2 388)) (#s(var res 386) 3 4) (#s(var a1 384) . 2) (#s(var a2 382) #s(var a1 384) . #s(var a2 385)) (#s(var res 383) 2 3 4) (#s(var a1 381) . 1) (#s(var a 379) #s(var a1 381) . #s(var a2 382)) (#s(var #f 0) #s(var a 379) #s(var b 380))) () () ())\n",
    "        == #s(var b 380) #s(var res 389)\n",
    "      bind\n",
    "        #f\n",
    "        == #s(var b 380) #s(var res 389)\n",
    "    bind\n",
    "      mplus\n",
    "        pause\n",
    "          #s(state ((#s(var a2 388) #s(var a1 390) . #s(var a2 391)) (#s(var res 389) 4) (#s(var a1 387) . 3) (#s(var a2 385) #s(var a1 387) . #s(var a2 388)) (#s(var res 386) 3 4) (#s(var a1 384) . 2) (#s(var a2 382) #s(var a1 384) . #s(var a2 385)) (#s(var res 383) 2 3 4) (#s(var a1 381) . 1) (#s(var a 379) #s(var a1 381) . #s(var a2 382)) (#s(var #f 0) #s(var a 379) #s(var b 380))) () () ())\n",
    "          == #s(var res 389) (#s(var a1 390) . #s(var res 392))\n",
    "        bind\n",
    "          #f\n",
    "          == #s(var res 389) (#s(var a1 390) . #s(var res 392))\n",
    "      (#<procedure:appendo> appendo #s(var a2 391) #s(var b 380) #s(var res 392))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12644efa-93a2-43cf-b1bb-46a67d41f073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  198,    27, 38604,  ..., 50256, 50256, 50256],\n",
       "        [  198,   220,   285,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text([sample_text_1, sample_text_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a71e8d7-a2b3-4fc4-913c-6f8dca8574a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "_text_embedding = nn.Embedding(_text_tokenizer.vocab_size, EMBEDDING_DIM)\n",
    "embed_text = _text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04278595-a4a5-44d7-8181-3c4efe2b5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dab67d3-0c60-4639-aed3-79ea674b9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand(device=device, generator=g):\n",
    "    return torch.rand((1,), device=device, generator=generator).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4175bfb1-76b8-4466-ae8a-5d2ad79d83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randint(low, high, device=device):\n",
    "    return torch.randint(low, high, (1,), device=device, generator=g).item()\n",
    "def rand01():\n",
    "    return randint(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b768419-a044-4626-a102-462a05465cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2Config, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2028640d-694d-4029-b183-a506a2db02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    configuration = GPT2Config(\n",
    "        n_layer=6,\n",
    "        n_head=6,\n",
    "        n_embd=EMBEDDING_DIM\n",
    "    )\n",
    "    model = GPT2Model(configuration)\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_optimizer(params):\n",
    "    optimizer = torch.optim.AdamW(params)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4675efc0-51c9-4a12-994d-7fcd58c6f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIM = 2\n",
    "linear = nn.Linear(SEQUENCE_LENGTH * EMBEDDING_DIM, OUT_DIM, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878d02d6-4e3f-4cea-a328-0cef167cb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_model = init_model().to(device)\n",
    "opt = init_optimizer(list(action_model.parameters()) + list(linear.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64a72081-ef9a-47b6-bd6f-2cef08d67d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = action_model(tokenize_text([sample_text_1, sample_text_2])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6734f41-a599-4254-a193-06056161343b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7033, 0.2967],\n",
       "        [0.7661, 0.2339]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(out.last_hidden_state.flatten(1)).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb84fb3c-213d-4748-94a4-31598347048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7033, 0.2967],\n",
       "        [0.7661, 0.2339]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(linear(out.last_hidden_state.flatten(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57af2710-dedc-4ff2-9737-4fe7178f15e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = action_model(tokenize_text([sample_text_1])[\"input_ids\"])\n",
    "out = linear(out.last_hidden_state.flatten(1))\n",
    "out = F.tanh(out)\n",
    "out = F.softmax(out, dim=1)\n",
    "out.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0935d00-a82b-4d83-8a64-b42328c7d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ɛ = 0.1\n",
    "terminated = False\n",
    "if rand() < ɛ:\n",
    "    action = rand01()\n",
    "else:\n",
    "    out = action_model(tokenize_text([sample_text_1])[\"input_ids\"])\n",
    "    out = linear(out.last_hidden_state.flatten(1))\n",
    "    out = F.tanh(out)\n",
    "    out = F.softmax(out, dim=1)\n",
    "    action = out.argmax(dim=1).item()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eefbf7a9-d570-4fa1-a19c-dc2c7a899a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n<INST>\\n(appendo a b '(1 2 3 4))\\nresults in order of how similar in length are a and b\\n</INST>\\n<STREAM>\\n\\nmplus\\n  conj\\n    #t\\n    (== 1 1)\\n\\n</STREAM>\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_action_prompt = \"\"\"\n",
    "<INST>\n",
    "(appendo a b '(1 2 3 4))\n",
    "results in order of how similar in length are a and b\n",
    "</INST>\n",
    "<STREAM>\n",
    "{stream}\n",
    "</STREAM>\n",
    "\"\"\"\n",
    "def make_action_prompt(s):\n",
    "    return initial_action_prompt.format(stream=s)\n",
    "make_action_prompt(\"\"\"\n",
    "mplus\n",
    "  conj\n",
    "    #t\n",
    "    (== 1 1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b670d3c8-e249-4b60-a650-d1e0d7971b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n<INST>\\n(appendo a b '(1 2 3 4))\\nresults in order of how similar in length are a and b\\n</INST>\\n<STREAM>\\n\\nmplus\\n  conj\\n    #t\\n    (== 1 1)\\n\\n</STREAM>\\n<ACTION>\\n1\\n</ACTION>\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_value_prompt = \"\"\"\n",
    "<INST>\n",
    "(appendo a b '(1 2 3 4))\n",
    "results in order of how similar in length are a and b\n",
    "</INST>\n",
    "<STREAM>\n",
    "{stream}\n",
    "</STREAM>\n",
    "<ACTION>\n",
    "{action}\n",
    "</ACTION>\n",
    "\"\"\"\n",
    "def make_value_prompt(s, a):\n",
    "    return initial_value_prompt.format(stream=s, action=a)\n",
    "make_value_prompt(\"\"\"\n",
    "mplus\n",
    "  conj\n",
    "    #t\n",
    "    (== 1 1)\n",
    "\"\"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a518fcb7-9c58-4b2e-a4f2-b6ba53dc38c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4762, 0.5238]], device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       " 1,\n",
       " tensor(0.5238, device='cuda:0', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = \"\"\"\n",
    "mplus\n",
    "  conj\n",
    "    #t\n",
    "    (== 1 1)\n",
    "\"\"\"\n",
    "out = action_model(tokenize_text([make_action_prompt(state)])[\"input_ids\"])\n",
    "out = linear(out.last_hidden_state.flatten(1))\n",
    "out = F.tanh(out)\n",
    "out = F.softmax(out, dim=1)\n",
    "action = out.argmax(dim=1).item()\n",
    "out, action, out[0][action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d79f348-20f4-4294-9d18-cd8aa9bc467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reward(observation):\n",
    "    if \"(1 2)\" in observation:\n",
    "        return 1\n",
    "    elif \"(1 2 3)\" in observation:\n",
    "        return 0.5\n",
    "    elif \"(2 3 4)\" in observation:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c26df-53d9-4862-9ac5-8c0024428f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bafba368-6154-45b3-968b-f4fb42e5767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zmq_init():\n",
    "    context = zmq.Context()\n",
    "    socket = context.socket(zmq.PAIR)\n",
    "    return context, socket\n",
    "\n",
    "def run_server(ctx, sock, port=5555):\n",
    "    print(f\"Binding to port {port}\")\n",
    "    while True:\n",
    "        message = sock.recv().decode(\"utf-8\")\n",
    "        if message.startswith(\"Success: \"):\n",
    "            pass\n",
    "        print(message.decode(\"utf-8\"))\n",
    "        choice = input(\"Choose a path [0, 1]: \")\n",
    "        try:\n",
    "            choice = int(choice)\n",
    "        except ValueError:\n",
    "            print(f\"Received {choice} but expected an integer. Try again.\")\n",
    "            continue\n",
    "        socket.send(struct.pack(\"!i\", choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9eb6f20b-ab28-455a-9ed6-5266be3cc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_observe(sock):\n",
    "    sock.RCVTIMEO = 50\n",
    "    poller = zmq.Poller()\n",
    "    poller.register(sock, zmq.POLLIN)\n",
    "    def observe():\n",
    "        result = []\n",
    "        while poller.poll(50):\n",
    "            events = poller.poll(50)\n",
    "            messages = []\n",
    "            for event in events:\n",
    "                messages.append(event[0].recv().decode(\"utf-8\"))\n",
    "            result.append(\"\\n\".join(messages))\n",
    "        return \"\\n\".join(result)\n",
    "    return observe\n",
    "\n",
    "def make_act(sock):\n",
    "    def act(action):\n",
    "        sock.send(struct.pack(\"!i\", action))\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e5463d2-f550-4a9a-a2ec-1c94648e333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SocketContext(connect='tcp://127.0.0.5:5555')>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx, sock = zmq_init()\n",
    "sock.connect(\"tcp://127.0.0.5:5555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9434796-f963-4b78-9920-152ac71f4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "poller = zmq.Poller()\n",
    "poller.register(sock, zmq.POLLIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5063bf47-7691-47f8-aff9-70818a17bb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poller.poll(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c993285-aa2f-45fc-8948-c541fa1ca693",
   "metadata": {},
   "source": [
    "### Actions, Observations, and Rewards, from reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2ff4bbad-c3fe-4bea-9b44-a46e08f7c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = make_act(sock)\n",
    "observe = make_observe(sock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "552d15b1-3fdd-476e-8fbf-498d939bd106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream:\n",
      "mplus\n",
      "  pause\n",
      "    #s(state ((#s(var #f 0) #s(var a 230) #s(var b 231))) () () ())\n",
      "    (#<procedure:appendo> appendo #s(var a 230) #s(var b 231) (1 2 3 4))\n",
      "  bind\n",
      "    #f\n",
      "    (#<procedure:appendo> appendo #s(var a 230) #s(var b 231) (1 2 3 4))\n",
      "\n",
      "\n",
      "Which path do you want to take? [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "b88cb473-6eb7-4ad4-ac74-19b279aafbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: (() (1 2 3 4))\n",
      "\n",
      "\n",
      "Stream:\n",
      "mplus\n",
      "  pause\n",
      "    #s(state ((#s(var res 234) 2 3 4) (#s(var a1 232) . 1) (#s(var a 230) #s(var a1 232) . #s(var a2 233)) (#s(var #f 0) #s(var a 230) #s(var b 231))) () () ())\n",
      "    == (1 2 3 4) (1 2 3 4)\n",
      "  bind\n",
      "    #f\n",
      "    == (1 2 3 4) (1 2 3 4)\n",
      "\n",
      "\n",
      "Which path do you want to take? [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take an action (0 or 1... left or right)\n",
    "act(0)\n",
    "# Take an observation\n",
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede8e3e-6a45-4bf7-a23d-9724f07095e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "act(0)\n",
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa1227-99d2-44c8-8d3b-04ae10a24e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [0, 0, 0]\n",
    "for p in path:\n",
    "    act(p)\n",
    "    print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "89451169-7cdb-4333-82e3-53a05ba0c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "cb03c57c-85df-4728-9b53-e25aa181c8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream:\n",
      "mplus\n",
      "  pause\n",
      "    #s(state ((#s(var #f 0) #s(var a 235) #s(var b 236))) () () ())\n",
      "    (#<procedure:appendo> appendo #s(var a 235) #s(var b 236) (1 2 3 4))\n",
      "  bind\n",
      "    #f\n",
      "    (#<procedure:appendo> appendo #s(var a 235) #s(var b 236) (1 2 3 4))\n",
      "\n",
      "\n",
      "Which path do you want to take? [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "ba491900-b9f4-40de-9eba-7f68c96bed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: ((1 2) (3 4))\n",
      "\n",
      "\n",
      "Stream:\n",
      "mplus\n",
      "  pause\n",
      "    #s(state ((#s(var b 236) 1 2 3 4) (#s(var a 235)) (#s(var #f 0) #s(var a 235) #s(var b 236))) () () ())\n",
      "    conj\n",
      "      == () ()\n",
      "      == (1 2 3 4) (1 2 3 4)\n",
      "  mplus\n",
      "    pause\n",
      "      #s(state ((#s(var b 236) 2 3 4) (#s(var a2 238)) (#s(var res 239) 2 3 4) (#s(var a1 237) . 1) (#s(var a 235) #s(var a1 237) . #s(var a2 238)) (#s(var #f 0) #s(var a 235) #s(var b 236))) () () ())\n",
      "      conj\n",
      "        == () ()\n",
      "        == (2 3 4) (2 3 4)\n",
      "    pause\n",
      "      #s(state ((#s(var res 245) 4) (#s(var a1 243) . 3) (#s(var a2 241) #s(var a1 243) . #s(var a2 244)) (#s(var res 242) 3 4) (#s(var a1 240) . 2) (#s(var a2 238) #s(var a1 240) . #s(var a2 241)) (#s(var res 239) 2 3 4) (#s(var a1 237) . 1) (#s(var a 235) #s(var a1 237) . #s(var a2 238)) (#s(var #f 0) #s(var a 235) #s(var b 236))) () () ())\n",
      "      conj\n",
      "        (#<procedure:appendo> appendo #s(var a2 244) #s(var b 236) (4))\n",
      "        == (3 . #s(var a2 244)) (3 . #s(var a2 244))\n",
      "        == (3 4) (3 4)\n",
      "\n",
      "\n",
      "Which path do you want to take? [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in path[:-1]:\n",
    "    act(p)\n",
    "    observe()\n",
    "act(path[-1])\n",
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "165f5303-5762-4a23-9e87-342b434a7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "act(0)\n",
    "print(observe())\n",
    "act(0)\n",
    "print(observe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fdf5c-792b-45a6-8348-8cc844b3cb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7410b4b-4f28-4471-87a2-8c0ca6df89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c7797e8-4c66-4341-8ea4-0b81aec1fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIM = 2\n",
    "linear = nn.Linear(SEQUENCE_LENGTH * EMBEDDING_DIM, OUT_DIM, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fe2a955-7962-4c7c-b48e-a0cac729aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_model = init_model().to(device)\n",
    "opt = init_optimizer(list(action_model.parameters()) + list(linear.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "408a5a53-eeab-4346-96d9-503148890b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m y[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m ((y \u001b[38;5;241m-\u001b[39m out)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rand() \u001b[38;5;241m<\u001b[39m ɛ:\n",
      "File \u001b[0;32m~/.virtualenvs/reason/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/reason/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/reason/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "α = 0.1\n",
    "ɛ = 0.1\n",
    "γ = 0.9\n",
    "\n",
    "opt.zero_grad()\n",
    "out = action_model(tokenize_text([make_action_prompt(\"\")])[\"input_ids\"])\n",
    "out = linear(out.last_hidden_state.flatten(1))\n",
    "out = F.tanh(out)\n",
    "out = F.softmax(out, dim=1)\n",
    "action = out.argmin(dim=1).item()\n",
    "act(action)\n",
    "observation = observe()\n",
    "\n",
    "if observation.startswith(\"Success: \"):\n",
    "    terminated = True\n",
    "    reward = calc_reward(observation)\n",
    "    y = torch.ones(out.shape, device=device)\n",
    "    y[0][action] = reward\n",
    "    loss = ((y - out)**2).mean(1) \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "else:\n",
    "    opt.zero_grad()\n",
    "    terminated = False\n",
    "    out = action_model(tokenize_text([make_action_prompt(observation)])[\"input_ids\"])\n",
    "    out = linear(out.last_hidden_state.flatten(1))\n",
    "    out = F.tanh(out)\n",
    "    out = F.softmax(out, dim=1)\n",
    "    action = out.argmin(dim=1).item()    \n",
    "    reward = out[0][action]\n",
    "\n",
    "while not terminated:\n",
    "    prev_reward = reward\n",
    "    prev_action = action\n",
    "    \n",
    "    reward = out[0][action]\n",
    "    reward = (1 - α) * prev_reward + α * γ * reward\n",
    "    y = torch.ones(out.shape, device=device)\n",
    "    y[0][action] = reward\n",
    "    loss = ((y - out)**2).mean(1)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if rand() < ɛ:\n",
    "        action = rand01()        \n",
    "\n",
    "    act(action)\n",
    "    observation = observe()\n",
    "    \n",
    "    if observation.startswith(\"Success: \"):\n",
    "        terminated = True\n",
    "        reward = calc_reward(observation)\n",
    "        reward = (1 - α) * prev_reward + α * γ * reward\n",
    "        y = torch.ones(out.shape, device=device)\n",
    "        y[0][action] = reward  \n",
    "        loss = ((y - out)**2).mean(1)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    else:\n",
    "        out = action_model(tokenize_text([make_action_prompt(observation)])[\"input_ids\"])\n",
    "        out = linear(out.last_hidden_state.flatten(1))\n",
    "        out = F.tanh(out)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        action = out.argmin(dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda068ca-01ca-4bab-8631-67bc17543144",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8fc7c-430c-45e3-9006-fb518efd3b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
